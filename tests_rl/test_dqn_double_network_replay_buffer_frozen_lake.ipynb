{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bbf530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laurent LEQUIEVRE\n",
    "# Research Engineer, CNRS (France)\n",
    "# Institut Pascal UMR6602\n",
    "# laurent.lequievre@uca.fr\n",
    "\n",
    "# https://unnatsingh.medium.com/deep-q-network-with-pytorch-d1ca6f40bfda\n",
    "\n",
    "# -> https://github.com/markusbuchholz/deep-reinforcement-learning/blob/master/dqn/solution/dqn_agent.py\n",
    "# -> https://markus-x-buchholz.medium.com/deep-reinforcement-learning-introduction-deep-q-network-dqn-algorithm-fb74bf4d6862\n",
    "\n",
    "\n",
    "# https://github.com/deligentfool/dqn_zoo/blob/master/DDQN/ddqn.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c2a7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "from collections import namedtuple, deque \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a84fd66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b9f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.envs.registration import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86eea928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove FrozenLakeNotSlippery-v0 from registry\n",
      "Number of states:  64\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "# If you got that error after a registration :\n",
    "# Error: Cannot re-register id: FrozenLakeNotSlippery-v0\n",
    "# So you need to delete an env registered\n",
    "\n",
    "env_dict = gym.envs.registration.registry.env_specs.copy()\n",
    "\n",
    "for env in env_dict:\n",
    "    if 'FrozenLakeNotSlippery-v0' in env:\n",
    "        print(\"Remove {} from registry\".format(env))\n",
    "        del gym.envs.registration.registry.env_specs[env]\n",
    "\n",
    "\n",
    "register(\n",
    "   id=\"FrozenLakeNotSlippery-v0\",\n",
    "   entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "   kwargs={'map_name': '8x8', 'is_slippery': False},\n",
    ")\n",
    "\n",
    "env = gym.make(\"FrozenLakeNotSlippery-v0\")\n",
    "print('Number of states: ', env.observation_space.n)\n",
    "print('Number of actions: ', env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a27eb522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of Holes = [19, 29, 35, 41, 42, 46, 49, 52, 54, 59]\n"
     ]
    }
   ],
   "source": [
    "def get_index_of_holes(an_env):\n",
    "    \n",
    "    env_list = [[c.decode(\"utf-8\") for c in line] for line in an_env.desc]\n",
    "    index_holes = []\n",
    "    \n",
    "    size = np.int64(np.sqrt(an_env.observation_space.n))\n",
    "    \n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            c = env_list[i][j]\n",
    "            if (c == 'H'):\n",
    "                index_holes.append(i*size+j)\n",
    "    return index_holes\n",
    "\n",
    "\n",
    "l = get_index_of_holes(env)\n",
    "\n",
    "print(\"Indexes of Holes = {}\".format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21a665c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed -size buffe to store experience tuples.\"\"\"\n",
    "    \n",
    "    def __init__(self, action_size, buffer_size, batch_size):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        \n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experiences = namedtuple(\"Experience\", field_names=[\"state\",\n",
    "                                                               \"action\",\n",
    "                                                               \"reward\",\n",
    "                                                               \"next_state\",\n",
    "                                                               \"done\"])\n",
    "        \n",
    "    def add(self,state, action, reward, next_state,done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experiences(state,action,reward,next_state,done)\n",
    "        self.memory.append(e)\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory\"\"\"\n",
    "        experiences = random.sample(self.memory,k=self.batch_size)\n",
    "        \n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float()\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long()\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float()\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float()\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float()\n",
    "        \n",
    "        return (states,actions,rewards,next_states,dones)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01b0a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.observation_space_size = state_size\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        obs_emb = F.one_hot(state.long(), num_classes=self.observation_space_size).squeeze()\n",
    "        x = F.relu(self.fc1(obs_emb.float()))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "db9f949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_action(action, env, indexes_of_holes):\n",
    "    new_state, reward, done, info = env.step(action)\n",
    "    index_of_goal = env.observation_space.n - 1\n",
    "    # Reward function\n",
    "    # if new_state is a Hole\n",
    "    #if new_state in [5, 7, 11, 12]:\n",
    "    if new_state in indexes_of_holes:\n",
    "        reward = -1\n",
    "    # else if new_state is the Goal (Final State)\n",
    "    elif new_state == index_of_goal:\n",
    "        reward = 1\n",
    "    # else penalize research\n",
    "    else:\n",
    "        reward = -0.01\n",
    "    return new_state, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ecd9a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            \n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(self.state_size, self.action_size)\n",
    "        self.qnetwork_target = QNetwork(self.state_size, self.action_size)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(self.action_size, BUFFER_SIZE, BATCH_SIZE)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "        \n",
    "    def choose_action(self, s):\n",
    "        if (np.random.rand(1) < 0.1): \n",
    "            #print(\"sample action !\")\n",
    "            #return self.env.action_space.sample()\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "        else:\n",
    "            agent_out = self.qnetwork_local(torch.tensor(s)).detach()\n",
    "            #print(agent_out)\n",
    "            index_max = np.argmax(agent_out)\n",
    "            #print(\"index max = {}\".format(index_max))\n",
    "            #print(\"torch max action !\")\n",
    "            return index_max.item()    \n",
    "        \n",
    "        \n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "            \n",
    "agent = Agent(state_size=env.observation_space.n, action_size=env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "7890c95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -1.97\n",
      "Episode 200\tAverage Score: -1.98\n",
      "Episode 300\tAverage Score: -1.76\n",
      "Episode 400\tAverage Score: -1.61\n",
      "Episode 500\tAverage Score: -1.79\n",
      "Episode 600\tAverage Score: -1.86\n",
      "Episode 700\tAverage Score: -1.79\n",
      "Episode 800\tAverage Score: -1.90\n",
      "Episode 900\tAverage Score: -1.71\n",
      "Episode 1000\tAverage Score: -1.87\n",
      "Episode 1100\tAverage Score: -1.85\n",
      "Episode 1200\tAverage Score: -1.72\n",
      "Episode 1300\tAverage Score: -1.79\n",
      "Episode 1400\tAverage Score: -1.39\n",
      "Episode 1500\tAverage Score: -0.97\n",
      "Episode 1600\tAverage Score: 0.111\n",
      "Episode 1700\tAverage Score: 0.44\n",
      "Episode 1800\tAverage Score: 0.58\n",
      "Episode 1900\tAverage Score: 0.71\n",
      "Episode 2000\tAverage Score: 0.64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def dqn(n_episodes=2000, max_t=200):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "    \"\"\"\n",
    "    indexes_of_holes = get_index_of_holes(env)\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    #eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, done, _ = take_action(action, env, indexes_of_holes)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        #eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        \"\"\"if np.mean(scores_window)>=200.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\"\"\"\n",
    "    return scores\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "edc4571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFF\u001b[41mF\u001b[0mF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFH\u001b[41mF\u001b[0m\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF\u001b[41mG\u001b[0m\n",
      "i = 1\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFF\u001b[41mF\u001b[0mF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFH\u001b[41mF\u001b[0m\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF\u001b[41mG\u001b[0m\n",
      "i = 2\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFF\u001b[41mF\u001b[0mF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFH\u001b[41mF\u001b[0m\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF\u001b[41mG\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"i = {}\".format(i))\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "            agent_out = agent.qnetwork_local(torch.tensor(state)).detach()\n",
    "            index_max = np.argmax(agent_out)\n",
    "            action =  index_max.item()    \n",
    "            env.render()\n",
    "            state, reward, done, _ = env.step(action)\n",
    "\n",
    "    env.render()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fae33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********** SOME TESTS *****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d81ae944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "action = agent.choose_action(state)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6de6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4ef65e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state of E is 2\n",
      "The action of E is 3\n",
      "The reward of E is -1\n",
      "The next state of E is 5\n",
      "The done of E is False\n"
     ]
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/namedtuple-in-python/\n",
    "# Declaring namedtuple()  \n",
    "Experience = namedtuple(\"Experience\", field_names=[\"state\",\n",
    "                                                               \"action\",\n",
    "                                                               \"reward\",\n",
    "                                                               \"next_state\",\n",
    "                                                               \"done\"])\n",
    "\n",
    "# Adding values  \n",
    "E = Experience(2,3,-1,5,False)  \n",
    "      \n",
    "# Access using index  \n",
    "print (\"The state of E is {}\".format(E.state))\n",
    "print (\"The action of E is {}\".format(E.action))\n",
    "print (\"The reward of E is {}\".format(E.reward))\n",
    "print (\"The next state of E is {}\".format(E.next_state))\n",
    "print (\"The done of E is {}\".format(E.done))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3c52e532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy vstack : Stack arrays in sequence vertically (row wise).\n",
    "# https://scipython.com/book/chapter-6-numpy/examples/vstack-and-hstack/\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "np.vstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "03405c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ACTION_SIZE = 4\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "buffer = ReplayBuffer(ACTION_SIZE, BUFFER_SIZE, BATCH_SIZE)\n",
    "\n",
    "states = [0, 1, 2, 3, 4, 5, 6, 7, 8 , 9 , 10, 11, 12, 13, 14, 15]\n",
    "actions = [0, 1, 2, 3, 0, 2, 1, 3, 0 , 0 , 1, 1, 2, 3, 3, 1]\n",
    "rewards = [0, 1, 2, 3, 4, 5, 6, 7, 8 , 9 , 10, 11, 12, 13, 14, 15]\n",
    "next_states = [0, 1, 2, 3, 4, 5, 6, 7, 8 , 9 , 10, 11, 12, 13, 14, 15]\n",
    "dones = [False, False, False, False, False, False, False, False, False, False,False, False, False, False, False,False]\n",
    "for i in range(16):\n",
    "    buffer.add(states[i], actions[i], rewards[i], next_states[i], dones[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c6d3696e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.],\n",
      "        [14.],\n",
      "        [13.],\n",
      "        [ 8.],\n",
      "        [11.]])\n",
      "tensor([[0],\n",
      "        [3],\n",
      "        [3],\n",
      "        [0],\n",
      "        [1]])\n",
      "tensor([[ 0.],\n",
      "        [14.],\n",
      "        [13.],\n",
      "        [ 8.],\n",
      "        [11.]])\n",
      "tensor([[ 0.],\n",
      "        [14.],\n",
      "        [13.],\n",
      "        [ 8.],\n",
      "        [11.]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "s, a, r, ns, d = buffer.sample()\n",
    "print(s)\n",
    "print(a)\n",
    "print(r)\n",
    "print(ns)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa8dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cc8615db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "state = torch.tensor(2).long().unsqueeze(0)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8ddab36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print(state)\n",
    "action = agent.choose_action(state)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2cd2612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.],\n",
      "        [14.],\n",
      "        [13.],\n",
      "        [ 8.],\n",
      "        [11.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ns)\n",
    "F.one_hot(ns.long(), num_classes=16).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "71a63a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.arange(4))\n",
    "\n",
    "random.choice(np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "67d8cc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.],\n",
      "        [ 9.],\n",
      "        [11.],\n",
      "        [15.],\n",
      "        [ 3.]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [3]])\n",
      "tensor([[ 0.],\n",
      "        [ 9.],\n",
      "        [11.],\n",
      "        [15.],\n",
      "        [ 3.]])\n",
      "tensor([[ 0.],\n",
      "        [ 9.],\n",
      "        [11.],\n",
      "        [15.],\n",
      "        [ 3.]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "s, a, r, ns, d = buffer.sample()\n",
    "print(s)\n",
    "print(a)\n",
    "print(r)\n",
    "print(ns)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9f1658a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns = tensor([[ 0.],\n",
      "        [ 9.],\n",
      "        [11.],\n",
      "        [15.],\n",
      "        [ 3.]])\n",
      "values = tensor([[ 0.8663,  0.8960,  0.8958,  0.8663],\n",
      "        [ 0.9194,  0.9604,  0.9603, -0.9999],\n",
      "        [ 0.6083,  0.8229,  0.6270,  0.9469],\n",
      "        [ 0.5293,  0.6252,  0.2518,  0.4082],\n",
      "        [ 0.9195, -1.0003,  0.8959,  0.8959]])\n",
      "vals = tensor([0.8960, 0.9604, 0.9469, 0.6252, 0.9195]), row_idx = tensor([1, 1, 3, 1, 0])\n",
      "max_values_per_lines = tensor([0.8960, 0.9604, 0.9469, 0.6252, 0.9195])\n",
      "tensor([[0.8960],\n",
      "        [0.9604],\n",
      "        [0.9469],\n",
      "        [0.6252],\n",
      "        [0.9195]])\n"
     ]
    }
   ],
   "source": [
    "print(\"ns = {}\".format(ns))\n",
    "values = agent.qnetwork_target(ns).detach()\n",
    "print(\"values = {}\".format(values))\n",
    "vals, row_idx = values.max(1)\n",
    "print(\"vals = {}, row_idx = {}\".format(vals, row_idx))\n",
    "\n",
    "max_values_per_lines = values.max(1)[0]\n",
    "print(\"max_values_per_lines = {}\".format(max_values_per_lines))\n",
    "\n",
    "print(max_values_per_lines.unsqueeze(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "efaeacd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_values = tensor([[ 0.8772,  0.8981,  0.9028,  0.8818],\n",
      "        [ 0.9197,  0.9622,  0.9671, -1.0005],\n",
      "        [ 0.6118,  0.8234,  0.6293,  0.9541],\n",
      "        [ 0.5296,  0.6284,  0.2552,  0.4142],\n",
      "        [ 0.9193, -1.0011,  0.9063,  0.9066]], grad_fn=<AddmmBackward>)\n",
      "actions = tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [3]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8772],\n",
       "        [0.9197],\n",
       "        [0.8234],\n",
       "        [0.6284],\n",
       "        [0.9066]], grad_fn=<GatherBackward>)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_values =  agent.qnetwork_local(ns)\n",
    "print(\"local_values = {}\".format(local_values))\n",
    "print(\"actions = {}\".format(a))\n",
    "local_values.gather(1,a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f936be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06460524])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e1afa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb372410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0078cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
